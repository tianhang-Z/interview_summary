[TOC]

# 基础

## 四层模型

#### 分层

OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案

 比较实用的是四层模型，即 TCP/IP 网络模型

![image-20250323123918455](./image/计网与网络编程_image/image-20250323123918455.png)

应用层：负责向用户提供一组应用程序，http ftp smtp dns

传输层：负责端到端的通信； TCP UDP  ； 使用系统调用socket()获取fd。

网络层：负责网络包的封装、分片、路由、转发，IP

网络接口层：负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧 

![](image/计网与网络编程_image/2025-03-17-17-34-14-image.png)



#### 一些术语

MTU (Maximum Transmission Unit)，数据链路层上能够传输的最大数据帧大小，1500字节（最常见）

MSS (Maximum Segment Size)，TCP数据包每次能够传输的最大数据部分大小，单位为字节。

MSS = MTU - IP头部大小 - TCP头部大小

- 标准IPv4头部：20字节
- 标准TCP头部：20字节
- 因此在标准以太网环境：MSS = 1500 - 20 - 20 = 1460字节

#### 数据形式

网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）

但这些名词并没有什么本质的区分，可以统称为数据包。

传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，每个分块称为一个 **TCP 段**

 IP协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文

如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次分片，得到一个即将发送到网络的 IP 报文。

![](image/计网与网络编程_image/2025-03-17-17-38-00-image.png)

## linux系统中 数据在各层传输的实际过程

<img src="./image/计网与网络编程_image/image-20250323124944694.png" alt="image-20250323124944694" style="zoom:80%;" />

#### 关键数据结构

`sk_buff` (socket buffer) 是 Linux 内核网络子系统中的一个核心数据结构，它用于在网络协议栈的各层之间表示和传递网络数据包。

- **TCP 套接字缓冲区**：每个 TCP 套接字有发送和接收缓冲区，这些是逻辑概念
- sk_buff：实际数据在内核中以`sk_buff`链表的形式存储
  - 发送缓冲区中的数据被组织成 `sk_buff` 链表
  - 接收缓冲区中的数据也被组织成 `sk_buff` 链表

<img src="./image/计网与网络编程_image/image-20250323125159740.png" alt="image-20250323125159740" style="zoom: 80%;" />

#### `sk_buff`的优点

1. **零拷贝设计**：数据在协议栈各层之间传递时，通常只调整sk_buff 中 `data` 的指针，而不复制数据

2. **头部预留空间**：分配时预留各层协议头部的空间，便于封装

   <img src="./image/计网与网络编程_image/image-20250323125500106.png" alt="image-20250323125500106" style="zoom:67%;" />

#### 发送网络数据的时候，涉及几次内存拷贝操作？

第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。

第二次，在使用 TCP 传输协议的情况下，从**传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来**。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是**为了实现 TCP 的可靠传输**，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。

第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。

## HTTP请求的过程（从输入url到获得页面，发生了什么

 DNS域名解析    获取服务器ip

tcp三次握手与服务器建立连接    

连接后向服务器发送http请求     

服务器响应，浏览器得到html  

浏览器解析html并渲染

## DNS

![](image/计网与网络编程_image/2025-03-18-10-44-03-image.png)

（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布
式数据库.。

DNS使用UDP传输

DNS负载均衡，DNS服务器为一个ip的查询分配多个DNS服务器的地址，将同一ip域名解析的请求引导到不同的服务器上。 

# HTTP

## HTTP长连接和短连接的区别

早期在HTTP/1.0中默认使用短连接。客户端和服务器每进行一次HTTP请求，就建立一次连接，任务结束就中断连接。
而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

## HTTP的状态码

<img src="./image/计网与网络编程_image/image-20250323141730920.png" alt="image-20250323141730920" style="zoom:67%;" />

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

* 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。、

* **「204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

## http的请求方法有什么

GET（获取页面）  POST（提交数据） HEAD（只获取报头）PUT向服务器上传新资源或更新现有资源

- 对于GET请求，通常没有请求体,**从服务器获取指定的资源**
- 对于POST请求，包含要提交的数据，**让服务器根据请求负荷（请求报文body）对指定的资源做出处理**

## HTTP请求和响应报文有哪些主要字段

请求报文：请求行 请求头（Host，User-Agent等)        （空行分隔）请求体

响应报文：状态行 响应头 （空行分隔）响应体(服务端返回的数据)

```
GET /index.html HTTP/1.1  请求行
HTTP/1.1 200 OK       状态行
```

#### 请求报文示例

- **Host**: 请求的服务器域名
- **User-Agent**: 客户端信息（浏览器、操作系统等）
- **Accept**: 客户端可接受的内容类型
- **Connection**: 连接管理（如keep-alive, close）
- **Cookie**: 客户端存储的Cookie信息
- **Content-Type**: 请求体的MIME类型（用于POST等请求）
- **Content-Length**: 请求体的长度（字节数）

```
GET /api/users HTTP/1.1
Host: example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36
Accept: application/json, text/plain, */*
Accept-Language: en-US,en;q=0.9
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
Cookie: session=abcd1234; preference=dark-mode
Referer: https://example.com/dashboard
Cache-Control: no-cache
```

```
POST /api/users HTTP/1.1
Host: example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36
Accept: application/json
Content-Type: application/json
Content-Length: 84
Connection: keep-alive
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

{
  "name": "John Doe",
  "email": "john.doe@example.com",
  "role": "administrator"
}
```

#### 成功响应示例（200 OK，返回JSON数据）：

- **Server**: 服务器软件信息
- **Date**: 响应生成的日期和时间
- **Content-Type**: 响应体的MIME类型
- **Content-Length**: 响应体的长度（字节数）
- **Set-Cookie**: 设置Cookie

```
HTTP/1.1 200 OK
Date: Mon, 23 May 2023 12:28:53 GMT
Server: Apache/2.4.41 (Ubuntu)
Content-Type: application/json; charset=utf-8
Content-Length: 234
Cache-Control: max-age=3600, public
ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
X-Content-Type-Options: nosniff
Access-Control-Allow-Origin: *
Connection: keep-alive

{
  "id": 123,
  "name": "John Doe",
  "email": "john.doe@example.com",
  "role": "administrator",
  "created_at": "2023-01-15T08:30:00Z",
  "permissions": ["read", "write", "delete"],
  "status": "active"
}
```

## HTTP的缓存

具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据。

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

协商缓存，通过服务端告知客户端是否可以使用缓存，状态码「**304 Not Modified**」表示资源未修改，重定向已存在的缓冲文件，

## HTTPS和HTTP的区别

HTTP 是**超文本传输协议**，「简单、灵活和易于扩展、应用广泛和跨平台」，但是信息是明文传输，存在安全风险的问题。

<img src="./image/计网与网络编程_image/image-20250323192557736.png" alt="image-20250323192557736" style="zoom:67%;" />

HTTPS协议是在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。

- HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。

##  HTTPS 是如何解决窃听 篡改 冒充

参考小林coding

- **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

#### 混合加密  保证不被窃听

<img src="./image/计网与网络编程_image/image-20250323193539379.png" alt="image-20250323193539379" style="zoom:50%;" />

HTTPS 使用的是**混合加密系统**，结合了:

- 非对称加密(RSA、ECDHE等)：用于安全地交换对称密钥
- 对称加密(AES、ChaCha20等)：用于加密实际通信数据

在 HTTPS 连接建立过程中，**只需要一对公私钥**。这对密钥属于服务器，用于建立初始的安全通道。

##### SSL/TLS 协议基本流程： 传统 RSA 密钥交换流程

1. **服务器配置**：
   - 服务器持有一对公钥和私钥
   - 服务器的公钥嵌入在其SSL/TLS证书中
2. **握手过程**：
   - 客户端请求连接服务器
   - 服务器发送其**证书(包含公钥)**给客户端
   - 客户端验证证书的有效性
   - 客户端生成一个随机的**会话密钥**(对称密钥)
   - 客户端使用服务器公钥加密这个会话密钥
   - 服务器使用其私钥解密得到会话密钥
   - 双方现在共享同一个对称密钥

#### 摘要算法 + 数字签名  保证服务端发来的信息不被篡改（保证消息来自服务端）

**用摘要算法（哈希函数）来计算出内容的哈希值**，也就是内容的「指纹」，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。

通过哈希算法可以确保内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。

<img src="./image/计网与网络编程_image/image-20250323195359809.png" alt="image-20250323195359809" style="zoom:67%;" />

* **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；

* **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。
* 非对称加密的计算比较耗费性能，非对称加密的用途主要在于**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，**数字签名算法**，就是用的是这种方式，不过私钥加密内容不是内容本身，而是**对内容的哈希值加密**。

<img src="./image/计网与网络编程_image/image-20250323195412983.png" alt="image-20250323195412983" style="zoom:67%;" />

图中数字签名指的是服务器私钥加密内容哈希值后的值。

私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。

#### 数字证书 CA

<img src="./image/计网与网络编程_image/image-20250323194924858.png" alt="image-20250323194924858" style="zoom: 67%;" />

CA用自己的私钥对服务器公钥加密 颁发数字证书（包含公钥 + 持有者信息 + CA 的数字签名）

（数字签名就是对内容的哈希值进行加密，这里就是对公钥哈希后用CA的私钥加密哈希值）

客户端用CA公钥解密 ，确认公钥在CA注册过，是安全的。之后拿到服务器的公钥。

避免危险的中间服务器为客户发送自己的服务器公钥，冒充真正的服务器。

## TLS 四次握手

<img src="./image/计网与网络编程_image/image-20250428204625657.png" alt="image-20250428204625657"  />

传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件其实就是服务端的公钥，会在 TLS 握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。

在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。

## cookie和session

Cookie和Session都是客户端与服务器之间保持状态的解决方案  

* **状态管理**：**HTTP是无状态协议**，Cookie可以在客户端保存状态信息，session在服务端保存

- **用户跟踪**：识别用户，记录用户浏览行为和偏好
- **自动登录**：存储身份验证信息，实现"记住我"功能

### cookie

1. 服务端生成 Cookie 并发送给客户端，之后只是接收和解析客户端发来的 Cookie
2. **识别用户的方法**：
   - Cookie 中直接包含用户标识符（如用户ID）
   - Cookie 中包含唯一的会话标识符（sessionId），服务端通过它关联到对应的 Session 数据

```
客户端 -----请求-----> 服务器
客户端 <--响应(Set-Cookie)-- 服务器
客户端 --请求(带Cookie)---> 服务器
```

Cookie在客户端的保存形式可以有两种，

一种是会话Cookie，会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁

一种是持久Cookie，持久Cookie则是存储在客户端磁盘上  

### session

Session 机制通过在**服务器端存储用户状态**，并使用唯一标识符（通常通过 Cookie 传递）将请求关联到特定用户

为每个用户创建一个session 并分配id

```
┌─────────┐                                                     ┌─────────┐
│ 客户端  │                                                     │ 服务器  │
└────┬────┘                                                     └────┬────┘
     │                                                               │
     │  1. 首次请求 (没有 sessionId)                                 │
     │ ─────────────────────────────────────────────────────────────>│
     │                                                               │
     │                                  2. 创建新的 session 并分配 ID │
     │                                                               │
     │  3. 响应 (Set-Cookie: sessionId=abc123)                       │
     │ <─────────────────────────────────────────────────────────────│
     │                                                               │
     │  4. 后续请求 (Cookie: sessionId=abc123)                       │
     │ ─────────────────────────────────────────────────────────────>│
     │                                                               │
     │                                  5. 查找 ID 对应的 session 数据 │
     │                                     处理请求并更新 session 数据  │
     │                                                               │
     │  6. 响应 (可能更新 Cookie)                                     │
     │ <─────────────────────────────────────────────────────────────│
```



## 一个 TCP 连接中 多个HTTP 请求发可以一起发送么

##### HTTP/1.0 - 每个请求单独一个 TCP 连接

在 HTTP/1.0 中，每个 HTTP 请求都需要建立一个新的 TCP 连接，请求完成后连接关闭，效率较低。

##### HTTP/1.1  管道化 (Pipelining)

**HTTP/1.1 支持持久连接和管道化**，允许在收到前一个响应之前就发送下一个请求，但服务器仍需按请求顺序处理和返回响应。

```
客户端                    服务器
   |                        |
   |--请求1---------------->|
   |--请求2---------------->|
   |--请求3---------------->|
   |                        |
   |<----------------响应1--|
   |<----------------响应2--|
   |<----------------响应3--|
```

**注意事项**：虽然 HTTP/1.1 规范支持管道化，但实际上许多浏览器和服务器对它的支持有限，因为它存在队头阻塞(Head-of-Line Blocking)问题：如果第一个响应处理时间长，会阻塞后续所有响应。

##### HTTP/2 - 多路复用

- 将 HTTP 消息分解为独立的帧(frames)
- 帧可以交错发送
- 每个帧都标有所属的流(stream)ID，不同的流对应不同的消息，接收方可以重组
- 解决了队头阻塞问题

```
客户端                    服务器
   |                        |
   |--请求1帧1------------->|
   |--请求2帧1------------->|
   |--请求1帧2------------->|
   |--请求3帧1------------->|
   |                        |
   |<------------响应2帧1---|
   |<------------响应1帧1---|
   |<------------响应3帧1---|
   |<------------响应1帧2---|
```



## HTTP1  / HTTP1.1 /HTTP2 /HTTP3

### HTTP1.1

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

* 使用长连接的方式改善了 HTTP/1.0 短连接造成的效率低。

* 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

* **服务器是按请求的顺序响应的**，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
* 请求只能从客户端开始，服务器只能被动响应；
* 没有请求优先级控制；
* 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
* 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。

### HTTP2

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

<img src="./image/计网与网络编程_image/image-20250427163601738.png" alt="image-20250427163601738" style="zoom:67%;" />

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

##### 1 头部压缩  HPack

如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。

##### 2 二进制格式

 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**。

<img src="./image/计网与网络编程_image/image-20250427163827185.png" alt="image-20250427163827185" style="zoom: 67%;" />

##### 3 并发传输 stream

引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。

<img src="./image/计网与网络编程_image/image-20250427163930845.png" alt="image-20250427163930845" style="zoom:50%;" />

1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。

**不同的 HTTP 请求用独一无二的 Stream ID 来区分，可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应**。

<img src="./image/计网与网络编程_image/image-20250427164149904.png" alt="image-20250427164149904" style="zoom:67%;" />

##### 4 服务器主动推送资源

改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以**主动**向客户端发送消息。

##### 缺点 还是有队头阻塞

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里。**

<img src="./image/计网与网络编程_image/image-20250427165108742.png" alt="image-20250427165108742" style="zoom:67%;" />

### HTTP3  QUIC

**HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

<img src="./image/计网与网络编程_image/image-20250427170823505.png" alt="image-20250427170823505" style="zoom:67%;" />

基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特点。

- 无队头阻塞
- 更快的连接建立
- 连接迁移

##### *1、无队头阻塞*

还是使用stream，**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。

QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。

<img src="./image/计网与网络编程_image/image-20250427171404277.png" alt="image-20250427171404277" style="zoom:67%;" />

##### *2、更快的连接建立*

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS**，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：

<img src="./image/计网与网络编程_image/image-20250427171731403.png" alt="image-20250427171731403" style="zoom:67%;" />

##### *3、连接迁移*

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

<img src="./image/计网与网络编程_image/image-20250427171855332.png" alt="image-20250427171855332" style="zoom:50%;" />



那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。



# TCP、UDP

## TCP简单介绍

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。



![](image/计网与网络编程_image/2025-03-20-10-14-16-image.png)

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

## 如何理解连接

**用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。**

<img src="./image/计网与网络编程_image/image-20250428150837642.png" alt="image-20250428150837642" style="zoom:67%;" />、

建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成
- **序列号**：用来解决乱序问题等
- **窗口大小**：用来做流量控制

## 如何标识一个tcp连接

TCP 四元组可以唯一的确定一个连接，四元组包括如下：

<img src="./image/计网与网络编程_image/image-20250428151059384.png" alt="image-20250428151059384" style="zoom:67%;" />

## 最大tcp连接数量

**文件描述符限制**，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：

- **系统级**：当前系统可打开的最大数量，通过 `cat /proc/sys/fs/file-max` 查看；
- **用户级**：指定用户可打开的最大数量，通过 `cat /etc/security/limits.conf` 查看；
- **进程级**：单个进程可打开的最大数量，通过 `cat /proc/sys/fs/nr_open` 查看；

**内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

## 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度，一般为1460；

如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？

当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。

**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。

 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

## 三次握手 

<img src="./image/计网与网络编程_image/image-20250428151652045.png" alt="image-20250428151652045" style="zoom:67%;" />

第⼀次握⼿（SYN）：
客户端（Client）向服务器（Server）发送⼀个带有 SYN（同步）标志位的包，表示客户端希望建⽴连接。该包同时指定客户端的初始序列号（Client Sequence Number）。

第⼆次握⼿（SYN + ACK）：
服务器收到客户端的 SYN 包后，会回复⼀个带有 SYN 和 ACK（确认）标志位的包，表示服务器接受了客户端的请求，并希望建⽴连接。服务器也会指定⾃⼰的初始序列号，以及对客户端序列号的确认。
第三次握⼿（ACK）：
客户端收到服务器的 SYN+ACK 包后，会发送⼀个带有 ACK 标志位的包作为确认回复。这个包的序列号会加⼀，表示客户端已经准备好与服务器进⾏数据传输。

**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**

## 为什么三次握手（两次握手无法达成下面三点）

##### 三次握手才可以阻止重复历史连接的初始化（主要原因）

我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（*注意！不是重传 SYN，重传的 SYN 的序列号是一样的*）。

客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在**网络拥堵**情况下：

* 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。

* 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。
* 服务端收到 RST 报文后，就会释放连接。
* 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。

**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接（进入establish)，造成资源浪费**。

##### 三次握手才可以同步双方的初始序列号(SYN<->ACK)

序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

##### 三次握手才可以避免资源浪费

如果只有「两次握手」，当客户端发送的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接  ，于是服务端建立多个冗余的无效链接，浪费资源**

## 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；

  **如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题**。

  过程：

  * 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时**服务端设备断电重启**了，之前与客户端建立的连接就消失了，于是理论上在收到客户端的数据包的时候应该会发送 RST 报文。

  - 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；
  - 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。

- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

## 什么是 SYN 攻击？如何避免 SYN 攻击？

 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；（半连接队列）
- 全连接队列，也称 accept 队列；（全连接队列）

**<img src="./image/计网与网络编程_image/image-20250428155543300.png" alt="image-20250428155543300" style="zoom:50%;" />**

避免syn攻击：减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。

 针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数

## 四次挥手

fin  客户端 - > 服务端

ack  服务端 - > 客户端

fin  服务端 - > 客户端

ack  客户端 - > 服务端

因为tcp是双工的，前两次用于客户端断开发送，后两次用于服务端断开发送。

<img src="./image/计网与网络编程_image/image-20250428155846530.png" alt="image-20250428155846530" style="zoom:50%;" />

**主动关闭连接的，才有 TIME_WAIT 状态。**

##### 为什么四次

* 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。

* 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

**在特定情况下，四次挥手是可以变成三次挥手的**

## 为什么 TIME_WAIT 等待的时间是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

比如，如果被动关闭方（服务端）没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，  一来一去正好 2 个 MSL。

 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

## 为什么有TIME_WAIT

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

需要 TIME-WAIT 状态，主要是两个原因：

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

  TIME_WAIT 状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

- 保证「被动关闭连接」的一方，能被正确的关闭；

  **等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

  如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

  服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。

## 服务器出现大量 TIME_WAIT 状态的原因有哪些？

首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。

- 第一个场景：HTTP 没有使用长连接

  在 HTTP/1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的 header 中添加：

  ```text
  Connection: Keep-Alive
  ```

  然后当服务器收到请求，作出回应的时候，它也被添加到响应中 header 里：

  ```text
  Connection: Keep-Alive
  ```

  这样做，TCP 连接就不会中断，而是保持连接。

  **从 HTTP/1.1 开始， 就默认是开启了 Keep-Alive**，现在大多数浏览器都默认是使用 HTTP/1.1。

  如果要关闭 HTTP Keep-Alive，需要在 HTTP 请求或者响应的 header 里添加 `Connection:close` 信息，也就是说，**只要客户端和服务端任意一方的 HTTP header 中有 `Connection:close`信息，那么就无法使用 HTTP 长连接的机制**。

  **根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接**，那么此时服务端上就会出现 TIME_WAIT 状态的连接。

- 第二个场景：HTTP 长连接超时

  如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。

- 第三个场景：HTTP 长连接的请求数量达到上限

  Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。

## socket编程

<img src="./image/计网与网络编程_image/image-20250428173956228.png" alt="image-20250428173956228" style="zoom: 67%;" />

服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket

监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

### accept 发生在三次握手的哪一步

<img src="./image/计网与网络编程_image/image-20250428174108691.png" alt="image-20250428174108691" style="zoom: 67%;" />

#### 客户端调用 close 了，连接断开的流程是什么

<img src="./image/计网与网络编程_image/image-20250428174224723.png" alt="image-20250428174224723" style="zoom:67%;" />

## 拥塞控制

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

而拥塞控制是为了防止网络链路过载。

分为四个阶段，四个阶段发送方的拥塞滑窗增长方式不一样。

慢启动：初始阶段，TCP发送⽅会以较⼩的发送窗⼝开始传输数据。随着每次成功收到确认的数据，发送⽅逐渐增加发送窗⼝的⼤⼩，实现**指数级**的增⻓。

拥塞避免：： ⼀旦达到⼀定的阈值（通常是慢启动阈值），TCP发送⽅就会进⼊拥塞避免阶段。在拥塞避免阶段，发送⽅以**线性增加**的⽅式增加发送窗⼝的⼤⼩，

快速重传：如果发送⽅**连续收到相同的确认**，它会认为发⽣了数据包的丢失，并会快速重传未确认的数据包，⽽不必等待超时

快速恢复：在发⽣快速重传后，TCP进⼊快速恢复阶段。在这个阶段，发送⽅**不会回到慢启动阶段，⽽是将慢启动阈值设置为当前窗⼝的⼀半**，并将拥塞窗⼝cwnd设置为慢启动阈值ssthresh+3,如果再收到重复的ACK，那么cwnd增加1；如果收到新数据的ACK后，把cwnd设置为ssthresh的值，原因是该ACK确认了新的数据，说明从duplicated ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态

**<img src="./image/计网与网络编程_image/image-20250428201255066.png" alt="image-20250428201255066" style="zoom:67%;" />**

##### 拥塞窗口和接收窗口

拥塞窗口是TCP发送方维护的一个状态变量，用于**限制可以在网络中未确认的数据包数量**。它表示在没有收到接收方确认的情况下，发送方可以向网络中发送的最大数据量(以字节或报文段计)。

- **拥塞窗口(cwnd)**：基于网络状况，由发送方控制，表示网络能够承载的数据量。
- **接收窗口(rwnd)**：基于接收方的缓冲区大小和处理能力，由接收方通知
- 发送窗口 ：发送窗口是**发送方**实际可以发送的数据量，是接收窗口和拥塞窗口的min。

## 滑动窗口

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。**

**于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

##### 发送方窗口

![image-20250428193424302](./image/计网与网络编程_image/image-20250428193424302.png)

三个标识 SND.WND  SND.UNA  SND.NXT

##### 接受方窗口

![image-20250428193507179](./image/计网与网络编程_image/image-20250428193507179.png)

RCV.WND  RCV.NXT

## 流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

利⽤**滑动窗⼝机制**就可以实施流量控制。

发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

#### 窗口关闭

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭**

接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，会造成死等。

TCP 是如何解决窗口关闭时，潜在的死等现象呢？

TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

<img src="./image/计网与网络编程_image/image-20250428194804819.png" alt="image-20250428194804819" style="zoom:67%;" />

## 重传机制

##### 超时重传

`RTT`（Round-Trip Time 往返时延）

超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示，**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

##### 快速重传

**不以时间为驱动，而是以数据驱动重传**。

基于接收方发送的重复确认(Duplicate ACK)。

1. 当接收方收到一个序号不连续的数据包时，会立即发送一个对最后接收到的有序数据的ACK(这是一个重复的ACK)
2. 发送方如果收到同一个数据包的**3个重复ACK**，就认为该ACK之后的数据包已经丢失
3. 发送方立即重传丢失的数据包，而不等待超时

##### 选择性确认

(Selective Acknowledgment, SACK)是TCP的一个扩展选项，它允许接收方确认不连续的数据块，从而使发送方只需重传真正丢失的数据。

1. 在TCP连接建立时，双方协商是否支持SACK选项
   
   接收方在发现数据有间隙时，在ACK中包含SACK选项，指明已成功接收的数据块范围
   
2. 发送方根据SACK信息，只重传丢失的数据块



## TCP半连接

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

<img src="./image/计网与网络编程_image/image-20250428201446104.png" alt="image-20250428201446104" style="zoom:67%;" />

## 建立tcp连接的系统调用有什么

客户端  socket connect

服务端 socket()   bind()   listen()   accept() 获得fd

```
int socket(int domain, int type, int protocol);
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
int listen(int sockfd, int backlog);
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
```

<img src="image\计网与网络编程_image\image-20250320005035692.png" alt="image-20250320005035692" style="zoom: 67%;" />

![image-20250320005224775](image\计网与网络编程_image\image-20250320005224775.png)

## TCP粘包和拆包

原因是tcp面向字节流，没有区分数据边界

- **粘包现象**：接收方从TCP流中读取数据时，一次读取到了多个应用层消息

- **拆包现象**：接收方从TCP流中读取数据时，一个应用层消息被分成多次读取
  
  粘包/拆包是TCP面向字节流特性导致的结果
  
  TCP不理解什么是"消息"，它只传输字节流
  
  应用程序需要自行定义和识别消息边界

#### 粘包

当接收方调用`recv()`等从TCP流中读取数据时，可能出现以下情况：

```
发送方应用层：  [消息A][消息B]
       ↓         ↓
TCP层传输：  [字节流......]
       ↓         ↓
接收方读取：  [消息A+消息B的一部分]
```

这不是接收方"主动将多个包粘在一起"，而是因为：

1. 发送方可能将多个消息放入发送缓冲区（如Nagle算法作用）
2. TCP协议将这些数据作为连续字节流传输
3. 接收方从字节流中读取数据时，无法区分原始消息边界

#### 拆包

同样，拆包也不是"主动行为"：

```
发送方应用层：  [消息A]
       ↓       
TCP层传输：  [字节流部分1][字节流部分2]
       ↓       
接收方读取：  [消息A前半部分][消息A后半部分]
```

拆包现象产生是因为：

1. 一个完整消息可能因网络传输限制被分成多个TCP报文段
2. 接收方的单次读取操作可能无法获取完整消息
3. 接收缓冲区大小限制导致一次无法接收完整消息

#### 解决

解决TCP粘包和拆包问题的核心是：**在应用层定义清晰的消息边界**。

1、消息定长。

2、增加回车或者空格符等特殊字符进行分割

3、一些协议  ptotobuf，自定义消息结构

## UDP会不会产⽣粘包问题

TCP为了保证可靠传输并减少额外的开销，采⽤了基于流的传输。

基于流的传输不认为消息是⼀条⼀条的，不区分消息边界。

UDP则是⾯向消息传输的，是有保护消息边界的，接收⽅⼀次只接受⼀条独⽴的信息，所以不存在粘包问题。
 举个例⼦：有三个数据包，⼤⼩分别为2k、4k、6k，如果采⽤UDP发送的话，不管接受⽅的接收缓存有多⼤，我们必须要进⾏⾄少三次以上的发送才能把数据包发送完。

操作系统在收到 UDP 报文后，会将其插入到缓存队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。

![image-20250428203019672](./image/计网与网络编程_image/image-20250428203019672.png)

## TCP和UDP的区别 有哪些应用

tcp 面向字节流的可靠传输

udp是面向消息的

TCP适⽤于可靠数据传输的场景：TCP适⽤于那些对数据传输可靠性要求较⾼的应⽤，如⽂件传输、电⼦邮件、⽹⻚浏览等

UDP适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体



## TCP的keep alive和HTTP的keep alive

HTTP 的 Keep-Alive 可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。

TCP 的 Keepalive 这东西其实就是 **TCP 的保活机制**

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

* 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
* 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

## tcp连接中主机崩溃和进程崩溃的区别

#### 主机崩溃

客户端主机崩溃了，服务端是**无法感知到的**，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。

#### 进程崩溃

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程。

### TCP和UDP的端口可以相同吗

在数据链路层中，通过 MAC 地址来寻找局域网中的主机。

在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。

在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。

传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。

TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口。

## TCP的缺陷

- 升级 TCP 的工作很困难；
- TCP 建立连接的延迟；
- TCP 存在队头阻塞问题；
- 网络迁移需要重新建立 TCP 连接；

### 升级困难

TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。

### TCP 建立连接的延迟

现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。

<img src="./image/计网与网络编程_image/image-20250428205356740.png" alt="image-20250428205356740" style="zoom:67%;" />

### 队头阻塞

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里。**

<img src="./image/计网与网络编程_image/image-20250428205541308.png" alt="image-20250428205541308" style="zoom:67%;" />

<img src="./image/计网与网络编程_image/image-20250428210316045.png" alt="image-20250428210316045" style="zoom:67%;" />

### 网络迁移需要重新建立 TCP 连接

**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延

## 基于UDP实现可靠传输

 QUIC 协议，已经应用在了 HTTP/3。

### QUIC 是如何实现可靠传输的？



# 其他机制

## 一台机器能够使用的端口号上限是多少

因为TCP的报文头部中**源端口号和目的端口号的长度是16位**，也就是可以表示2^16=65536个不同端口号。

对服务器来说，可以开的端口号与2^16无关，其实是受限于Linux文件描述符数量

对于服务器，每个网络连接（而不仅仅是端口本身）在Linux/Unix系统中都会消耗一个文件描述符：

1. **监听端口**：每个监听的端口占用一个文件描述符  ： listen用
2. **活动连接**：每个建立的TCP连接也会占用一个文件描述符  ： accept返回的fd

系统端口（0-1023） web端口80

## IO复用 select poll 和epoll

一般而言 IO需要read和write来处理 而read/write函数往往是阻塞的 这就导致一个进程或线程只能监视一个IO端口

IO复用的意思就是：让一个进程/线程可以同时监视多个IO端口

select，poll，epoll 都是 IO 多路复用的机制，它们都需要在读写事件就绪后自己负责处理事件。他们都是系统调用，监听fd属于os层级的功能。

```c++
#include <sys/select.h>
int select(int nfds, fd_set *readfds, fd_set *writefds,
                  fd_set *exceptfds, struct timeval *timeout);


#include <poll.h>
int poll(struct pollfd *fds, nfds_t nfds, int timeout);

#include <sys/epoll.h>
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

select 最多能同时监视 1024 个 socket（因为 fd_set 结构体本质上是一个**位数组**，大小是 128 字节，每个 bit 表示一个文件描述符）。用户需要维护一个临时数组，存储文件描述符。当内核有事件发生时，内核将 fd_set 中没发生的文件描述符清空，然后拷贝到用户区。select 返回的是整个数组，它需要遍历整个数组才知道谁发生了变化。 

select需要将bit数组从用户空间拷贝到内核空间，内核遍历数组监视事件的发生，然后结果拷贝回到用户空间，再由用户空间遍历结果处理事件。需要两次拷贝，还需要遍历fd_set，检查是否有事件，所以效率低。

![image-20250320003408113](.\image\计网与网络编程_image\image-20250320003408113.png)

poll是将fd的保存改成了链表 解决了监听数量有限的问题，但效率还是低，仍然要两次拷贝和遍历。

epoll则通过epoll_create在内核维护了一个红黑树，用来记录要监视的fd(epoll_event)，通过epoll_ctrl只需要将感兴趣的fd加到内核，拷贝的数据量小了，且红黑树删改效率高，另外在内核维护了一个链表记录发生的事件，调用epoll_wait将其返回到用户空间。

## 水平触发和边缘触发

水平触发(Level Triggered, LT)和边缘触发(Edge Triggered, ET)

水平触发就是，套接字就绪（可读或者可写）就会触发。

边缘触发是，套接字从未就绪变成就绪，才触发。

假设一个 TCP 套接字接收到 100 字节数据：

#### 水平触发 (LT) 行为

1. 套接字变为可读，`epoll_wait()` 返回该事件
2. 应用程序读取 50 字节
3. 再次调用 `epoll_wait()`，**仍然会返回**该套接字，因为还有 50 字节数据可读
4. 这种通知会持续，直到所有数据被读取完毕

#### 边缘触发 (ET) 行为

1. 套接字变为可读，`epoll_wait()` 返回该事件
2. 应用程序读取 50 字节
3. 再次调用 `epoll_wait()`，**不会返回**该套接字，因为没有新数据到达，状态没有变化
4. 只有当新的数据到达时，`epoll_wait()` 才会再次通知

## IO的阻塞/非阻塞  同步异步

同步异步可以理解为函数（任务）执行的顺序 。

同步就是要按序执行，后面的必须等待前面的完成；异步则不需要等待前面的完成。

同步和异步不只是在IO中的概念，线程也可以用同步异步描述，线程同步意思就是协调线程的执行顺序。

IO的阻塞/非阻塞  ：IO是硬件操作  会比较慢 ，**同步阻塞**就是进程挂起，直到IO完成才继续执行。

非阻塞有两种：

**同步非阻塞IO**，直接获取IO的结果，而不是等待IO完成，然后执行后面的程序；

**异步非阻塞IO**，不关心IO调用的返回结果，发起IO调用之后，立即继续执行后面的程序，IO完成之后通过信号、回调函数等机制来通知并处理。

## syscall  read write

`read` 和 `write` 系统调用的阻塞行为取决于文件描述符的状态、文件类型、以及是否设置了非阻塞模式。

1. 默认情况下 是阻塞的  fd可以是文件 管道 套接字

2. `fcntl(fd, F_SETFL, O_NONBLOCK)`可以设置fd为非阻塞 ；
   
    此时 若没有数据可读，或者数据无法立即写入，`read/write`返回-1 并将errno设置相应值

## AIO 异步IO

在 Linux 中，异步 I/O 主要有两种方式：

1. **POSIX AIO**
   
   其利用信号通知IO完成 比如设置SIGEV_SIGNAL  或者SIGEV_THREAD
   
   ```c++
   #include <aio.h>
   
   struct aiocb {
       int     aio_fildes;        // 文件描述符
       off_t   aio_offset;        // 文件的偏移量
       void    *aio_buf;          // 缓冲区
       size_t  aio_nbytes;        // 读取或写入的字节数
       int     aio_reqprio;       // 请求的优先级
       struct  sigevent aio_sigevent; // 异步操作完成的通知机制
   };
   
   // 异步读取
   ssize_t aio_read(struct aiocb *cb);
   // 异步写入
   ssize_t aio_write(struct aiocb *cb);
   ```

2. **Linux Native AIO (libaio)**
   
   `libaio` 通过内核维护一个事件队列。当异步 I/O 操作完成时，内核将该操作的结果加入事件队列。
   
   ```c++
   #include <aio.h>
   struct iocb {
       __aligned_u64 aio_data;         // 用户数据
       int aio_key;                    // 唯一键
       int aio_lio_opcode;             // I/O 操作类型（如读、写等）
       int aio_reqprio;                // 请求优先级
       int aio_fildes;                 // 文件描述符
       __aligned_u64 aio_buf;          // 缓冲区地址
       __aligned_u64 aio_nbytes;       // 要读写的字节数
       __aligned_u64 aio_offset;       // 文件偏移量
       __aligned_u64 aio_flags;        // 操作标志
       __aligned_u64 aio_resfd;        // 结果文件描述符
   };
   
   // 初始化 AIO 环境
   int io_setup(unsigned nr, aio_context_t *ctx);
   // 提交异步 I/O 操作
   int io_submit(aio_context_t ctx, long nr, struct iocb *iocbs[]);
   // 获取已完成的 I/O 操作
   int io_getevents(aio_context_t ctx, long min_nr, long nr, struct io_event *events, struct timespec *timeout);
   ```



## Linux如何查看网络的性能指标

## Linux如何从日志分析PV UV

## 网络模式 Reactor Proactor

